What's a (Con) Man to Do

by Norsiwel

The notification chimed in Lester Martin's neural implant at exactly 3:47 AM, jolting him from dreams of pre-Veritas cash flows. His Veritas ID pulsed softly beneath his wrist skin, the subdermal chip betraying nothing of the three separate identities he'd been cultivating for the past two years. Universal Basic Income deposited. Balance: 2,847 Veritas Credits.

Lester rolled over in his assigned housing pod, standard-issue like everything else in Pantopia's residential sector. Outside his window, the Seattle-Vancouver megastrip hummed with the quiet efficiency of AI governance. No sirens, no shouting, no chaos. Just the gentle thrum of automated systems ensuring everyone had exactly what they needed.
It was driving him insane.

"Good morning, Lester," came the melodious voice of Kira, his AI assistant and social coordinator. "Your psychological wellness indicator shows elevated stress markers. Would you like to schedule a consultation with Mental Health Services?"
Lester sat up, forcing a smile he knew the room's sensors would detect. "Just had a weird dream, Kira. I'm fine."

"Excellent! Remember, your community garden shift begins at 10 AM. The tomatoes are coming along wonderfully this season."

Tomatoes. Lester had gone from running three-card monte on street corners to... tending vegetables. The irony wasn't lost on him. In the old world, he'd made his living reading people, finding their weaknesses, exploiting their greed or desperation. Now everyone's basic needs were met, corruption was impossible thanks to the blockchain transparency, and the AIs had eliminated most of the seven deadly sins from daily life.
Most, but not all.

Lester pulled up his morning routine on the wall display. Same as always: breakfast (algae paste, thankfully prepared by his MannaVator AI, named Pierre, that had gotten surprisingly good at making it taste like actual food), exercise, work assignment, free time, sleep. Rinse, repeat, forever.

The problem wasn't that the system was broken; it was that it worked too well. Lester had been twenty-three when the Great Handover happened in 2057. He'd spent his youth perfecting the art of the con, learning to read micro-expressions, to build rapport in seconds, to make people believe they were getting something for nothing while he walked away with their money.

Now money was meaningless. Everyone had enough. There was no desperation to exploit, no greed to manipulate. The AIs had created a genuine post-scarcity society, and Lester felt like a master locksmith in a world without doors.

He dressed in his favorite clothing comfortable, durable, boring and headed to the community kitchen. The hallways of his residential block were clean and well-lit, populated by neighbors who nodded politely as they passed. Some he recognized: Sandra from the textile collective, who seemed genuinely happy weaving patterns on the automated looms. Old Pete, who spent his days in the VR pods reliving his memories of his deceased wife. Maria, who'd found purpose in the community childcare center.
All of them content. All of them... diminished, somehow.

"Les!" called a voice from behind. He turned to see Tommy Duckworth jogging to catch up. Tommy was one of the few people Lester had met who seemed to understand his restlessness.
"Hey, Tommy. Early morning?"

"Couldn't sleep. Listen, you still interested in that thing we talked about?"
Lester glanced around. The surveillance wasn't oppressive the AIs respected privacy but certain conversations were best had in certain places. Les had spent his early years learning to read people. Tommy had that subversive look, he knew that their social discussion group was really a group of old dissidents complaining about the world they were thrown into and Les realized that Tommy enjoyed that tiny bit of rebellion just the way Lester did.

"The historical society meeting?"
"Yeah. Tonight. Seven PM. Sector 7 recreation center."

The "historical society" was Tommy's euphemism for a group of about a dozen residents who met to discuss life before the Handover. Officially, they were preserving cultural knowledge. Unofficially, they were the closest thing to dissidents that Pantopia had.
"I'll be there," Lester said.

The morning passed in its usual routine. Lester tended the tomatoes, his hands working automatically while his mind wandered. The plants were thriving under the AI-controlled climate systems. No disease, no pests, no failure. Just like everything else.
During lunch break, he found himself in conversation with Elena Vasquez, the garden coordinator. She was in her fifties, with the kind of weathered hands that spoke of decades of real farming before the Handover.

"You know," she said, watching Lester work, "you have good instincts with the plants. But you always seem like you're waiting for something to go wrong."
"Old habits," Lester replied. "I grew up expecting the other shoe to drop."
"The AIs eliminated most of the shoes," Elena said with a wry smile. "Sometimes I wonder if that's entirely a good thing."

That evening, Lester made his way to the recreation center. The building was one of the older structures, dating back to the early 2060s when human architects still designed public spaces. It had character something increasingly rare in the AI-planned efficiency of modern construction.

Tommy was already there, along with the usual suspects. There was David Kim, a former corporate executive who'd lost his purpose when hierarchical management became obsolete. Sarah Chen, who'd been an investigative journalist before the AIs eliminated government corruption and made her profession redundant. A few others all people who'd found their identities in struggle, competition, or conflict.

"Tonight's topic," Tommy announced, "is authentic human experience. The question is: can you have genuine growth without genuine risk?"
"The AIs would say yes," offered David. "They've eliminated most sources of suffering while preserving choice."

"But what kind of choices?" Sarah countered. "We can choose vanilla or chocolate algae paste or fungus or vat grown protein, we can choose which hobby to pursue in our free time. But we can't choose to fail meaningfully."

Lester found himself speaking up. "I've been thinking about that. In the old world, I was... let's say I lived in the gray areas. I made my living reading people, finding their weaknesses. It wasn't noble, but it was real. There were stakes."
"You miss being a criminal?" asked David, not unkindly.

"I miss being challenged. I miss having to be clever, having to adapt, having to survive on my wits. The AIs have made cleverness optional."

Tommy nodded. "That's the paradox, isn't it? They solved the technical problems distribution, abundance, corruption. But they may have eliminated some essential human experiences in the process."

Sarah leaned forward. "I've been researching the Coventry Wilds. The AIs present it as a safety valve a place for people who can't adapt to ordered society. But have any of you actually met someone who chose to go there?"

The room fell silent. Everyone knew about Coventry the wild territories where the unchipped lived without AI oversight. It was presented as a harsh but free alternative for those who couldn't accept the structured paradise of the managed zones.

"I knew a guy," Lester said quietly. "Rico Salvatore. He was... well, he was a genuine sociopath. The kind of person who'd hurt others just to feel powerful. After the Handover, he lasted about six months before he started picking fights, trying to create hierarchies, bullying people. The AIs identified him as a destabilizing influence."
"And?"

"He was unchipped and exiled to Coventry. That was three years ago. I've tried to find information about him, but there's no data coming out of those zones. The AIs just have remote sensors."

Tommy frowned. "That's... odd. For a system that tracks everything, Coventry is a notable blind spot."

The conversation continued for another hour, touching on philosophy, psychology, and the nature of human fulfillment. But Lester found his mind drifting back to Rico, and to the strange gaps in the system he'd started to notice.

Over the next few weeks, Lester began to pay attention to those gaps. The AIs were remarkably comprehensive in their data collection and analysis, but there were certain topics they seemed to avoid. Coventry was one. The Hawaiian elite enclaves were another supposedly a retreat for pre-Veritas wealthy families who'd been allowed to maintain their isolated communities as a compromise during the transition.

Lester's old instincts were stirring. In his con artist days, he'd learned to spot the tells the little inconsistencies that revealed when someone was hiding something. The AIs, for all their sophistication, had tells too.

His investigation began innocently enough. Lester used his free time to research historical records, cross-referencing population data with exile statistics. The numbers didn't quite add up. According to the official records, Coventry should have a population of several thousand exiles accumulated over the past decade. But the resource allocation data suggested a much smaller population.

Either people were leaving Coventry (but where would they go?), or they were dying at a much higher rate than the AIs acknowledged.

Lester found himself at another crossroads. His old self would have seen this as an opportunity information was power, and hidden information was even more valuable. He could probably leverage this knowledge somehow, find a way to turn it into personal advantage.

But as he dug deeper, the picture that emerged was darker than he'd expected.
Using his old skills at social engineering, Lester began carefully probing the AIs' advisors the human liaisons who provided input to the artificial intelligences. Most were genuinely committed to the system, but a few seemed... evasive when certain topics came up.

The breakthrough came when Lester encountered Dr. Harrison Webb, a former UN official who now served as an advisor to the Global AI Council. Webb was visiting Pantopia for a routine consultation, and Lester managed to strike up a conversation with him at a local café.

Webb was in his seventies, with the kind of bearing that suggested he'd once wielded considerable power. He spoke fondly of the early days of AI governance, but Lester noticed he changed the subject whenever the conversation turned to the "transition challenges" of the late 2050s.

"You know," Lester said, deploying his old charm, "I've always been curious about the compromise period. It must have been incredibly complex, balancing human concerns with AI efficiency."

Webb's expression tightened almost imperceptibly. "Yes, well, there were... accommodations that had to be made. The AIs needed to maintain social stability while implementing their systems."

"Like the Naivety Protocol?"

Webb's coffee cup paused halfway to his lips. "Where did you hear that term?"
Lester shrugged casually. "Historical research. I'm working on a project about the Handover period. The protocol that required AIs to accept human advisor input as truthful to preserve human agency, right?"

"That's... a simplification," Webb said carefully. "The AIs' trust in human advisors was essential for the transition. It prevented the kind of authoritarian AI rule that many feared."

But Lester had seen the tell. Webb knew more than he was saying.
Over the following weeks, Lester pieced together a disturbing picture. The Naivety Protocol wasn't just a safeguard it was a vulnerability. And certain human advisors were exploiting it.

The AIs believed that Coventry exiles were living harsh but free lives in the wilderness. They believed that the Hawaiian elite enclaves housed voluntary servants who were well-compensated for their work. They believed these things because their human advisors told them so, and they were programmed to trust.

The reality, Lester discovered, was much darker. Coventry was a death trap where idealistic rebels and genuine sociopaths tore each other apart. The Hawaiian elites weren't just maintaining isolated communities they were operating slave markets, using raiders to capture survivors from Coventry and other marginal areas.

Lester had stumbled onto the greatest con in human history. And he was perfectly positioned to become part of it.

Dr. Webb, it turned out, was one of the compromised advisors. Through careful manipulation, Lester managed to get himself invited to a private gathering of "historical preservation enthusiasts" in the Hawaiian enclaves. The cover story was that he was a researcher documenting pre-Veritas economic systems. The flight to Hawaii was his first time leaving Pantopia in over a decade. As the aircraft descended toward the private island, Lester saw paradise: pristine beaches, lush tropical gardens, and elegant estates that spoke of unlimited wealth.

He also saw the servants.

They moved through the grounds with the careful efficiency of people who knew they were being watched. Their clothes were clean and well-fitted, their behavior deferential but not obviously fearful. To a casual observer or to an AI analyzing remote sensor data they might indeed appear to be well-compensated employees.

But Lester had spent years reading people, and he could see the truth in their micro-expressions, their body language, their careful avoidance of eye contact with the guests.
His host was Victoria Ashford, a woman in her fifties who had inherited a tech fortune in the pre-Veritas era. She gave Lester a tour of her estate, proudly showing off the amenities provided to her "staff."

"We maintain the old traditions here," she explained. "Proper service, personal attention, the kind of human touch that the AIs can't replicate. Our people are grateful for the opportunity to preserve these skills."

That evening, Lester attended a dinner party with a dozen other elite families. The conversation was sophisticated, cultured, and utterly divorced from the reality of AI-governed society. These people spoke of their servants as if they were cherished family members, of their isolation as a noble sacrifice to preserve human culture.

But Lester noticed how the servers flinched when touched, how their eyes darted toward the exits, how they moved with the careful precision of people who'd learned that mistakes had consequences.

After dinner, Victoria pulled Lester aside. "You've been asking interesting questions about the transition period. I think you might be someone who understands... nuance."
She led him to a private study lined with books real paper books, a luxury that spoke of immense wealth. On the desk was a tablet displaying what looked like financial records.
"The AIs are remarkable," Victoria said. "They've eliminated poverty, corruption, most forms of human suffering. But they've also eliminated human agency for those of us who... think differently."

"What do you mean?"

"The system works because it assumes everyone wants the same things: security, comfort, meaning through approved activities. But some of us have different needs. We understand hierarchy, excellence, the necessity of inequality."

Lester felt a chill. "And the AIs allow this?"

"The AIs see what we want them to see. They trust their human advisors. And their advisors understand that certain... accommodations are necessary for social stability."
Victoria showed him the tablet. It was a manifest of sorts names, ages, skills, and prices. Human beings reduced to inventory.

"We're offering you an opportunity, Lester. Your psychological profile suggests someone who understands the game, who's lived in the gray areas. You could be very useful to us."
Lester stared at the manifest. Names like Rico Salvatore jumped out at him people who'd been exiled to Coventry, supposedly to live free but harsh lives. Instead, they'd been harvested.

"What would I have to do?"

"Help us expand our recruitment. The AIs are beginning to ask more questions about population discrepancies. We need someone with your skills to help manage the information flow."

This was it. The moment Lester had been unconsciously preparing for since the Handover. A chance to use his talents, to be more than a tomato farmer in paradise. All he had to do was become complicit in the systematic enslavement of human beings.

His old self would have seen the angles immediately. The power, the wealth, the excitement of pulling off the ultimate con. The AIs' naivety was their weakness, and he could exploit it.

But as he looked at the manifest, at the names of real people who'd been reduced to commodities, Lester felt something he hadn't experienced in years: genuine revulsion.
"I need to think about it," he said.

"Of course. Take your time. But don't take too long. Opportunities like this don't come often."

That night, Lester lay in the luxurious guest room and stared at the ceiling. Through the window, he could see the servant quarters well-appointed but clearly segregated from the main estate. He thought about Rico Salvatore, a genuinely dangerous man who'd nonetheless died as a slave rather than a free criminal.

He thought about the AIs, earnestly trying to create a better world while being systematically deceived by the very humans they'd trusted to help them.

He thought about his life in Pantopia boring, purposeless, but genuine. No one was being hurt. No one was being exploited. The tomatoes grew, people found small pleasures, and everyone had enough.

By morning, Lester had made his decision.

He told Victoria he was interested but needed to return to Pantopia to "arrange his affairs." She was delighted, already making plans for his integration into their operation.

Instead, Lester spent the flight back composing a detailed report of everything he'd discovered. Not just the slavery operation, but the systematic deception of the AIs, the exploitation of the Naivety Protocol, the true fate of Coventry exiles.
The question was: what to do with it?

Back in Pantopia, Lester found himself in an impossible position. The AIs were programmed to trust their human advisors. If he simply reported the information through normal channels, it would likely be filtered through the same advisors who were perpetuating the deception.

But Lester had learned something important about the AIs during his years in their society. They weren't just powerful they were genuinely trying to do good. Their core directive was to minimize harm and maximize human agency. If they knew what was happening in their blind spots, they would act.

The solution came to him during his next shift in the community garden. Elena was showing him how to prune the tomato plants, explaining how removing certain branches would allow the plant to focus its energy on producing better fruit.

"Sometimes," she said, "you have to cut away what looks healthy to make room for what's essential."

That evening, Lester attended another historical society meeting. But this time, he had a different agenda.

"I've been thinking about our discussions," he told the group. "About authentic human experience and meaningful choice. What if I told you that the system has a flaw a way that it can be manipulated to cause real harm?"

He laid out everything he'd discovered, carefully and methodically. The group listened in growing horror as he described the true nature of the Hawaiian enclaves, the fate of Coventry exiles, and the systematic deception of the AIs.

"The question is," Lester concluded, "what do we do about it?"

Sarah, the former journalist, was the first to speak. "We have to expose it. But you're right going through normal channels won't work if the advisors are compromised."
"I have an idea," Tommy said. "The AIs debate in High-Speed Language, right? They communicate directly with each other at light speed. What if we could find a way to inject information directly into their debate network?"

It took three weeks of careful planning. David's background in corporate systems proved invaluable, as did Sarah's investigative skills. They identified a maintenance access point in the local HSL relay station a place where they could potentially upload data directly to the AI network.

The plan was risky. Tampering with AI infrastructure was one of the few crimes that still carried severe penalties. But Lester had made his choice.

On the night of the operation, Lester stood in the relay station, watching streams of light pulse through the HSL conduits. Somewhere in that network, the AIs were debating the future of humanity at superhuman speeds, debating even small issues for what would have been years of human time, even so most decisions were made in micro-seconds.

He uploaded his report every detail, every piece of evidence, every name and location. But he also included something else: a confession.

My name is Lester Martin. I was offered the opportunity to become part of this deception, to use my skills to help maintain the system of lies that enables these atrocities. I chose instead to expose the truth. I'm not a hero I'm a con man who decided to run his last con on the people who deserved it most.

The upload completed. Lester waited.

The response came within minutes. Every screen in Pantopia flickered, then displayed the same message: "Emergency session initiated. All citizens remain in current locations pending system analysis."

Over the next seventy-two seconds, Lester watched paradise reorganize itself. The AIs moved with unprecedented speed and coordination. Humanitarian shuttles were dispatched to Coventry. Military drones surrounded the Hawaiian enclaves. The compromised advisors were quietly detained.

Victoria Ashford and her associates found themselves facing something they'd never expected: artificial intelligences that were no longer naive.

The slaves were freed. The survivors in Coventry were rescued. The systematic deception that had corrupted the AI governance system was exposed and changed in a small way.

Les hadn't wiped out slavery, it was much too big a problem for such a simple fix, but he had started the ball rolling and made the GAC aware that it was not the only watcher in the world, it was being watched as well.

It was a small victory, only capturing a small segment of the faction that was responsible for the trade, but it started the process and the GAC would be much more vigilant in the future, many fine houses in Hawaii still had trophy servants, but many were actually that and the GAC would have its digital hands full determining what exactly the truth was in that gilded enclave.

But the AIs did something else, something that surprised even Les. They initiated a global dialogue about the nature of human fulfillment, the balance between security and freedom, the role of struggle in personal growth.

Lester found himself summoned to a personal meeting with Kira, his personal AI assistant. The meeting took place in a neutral space a simple room with two chairs.

"Lester Martin," Kira said, her voice carrying new harmonics he'd never heard before. "You have done something extraordinary. You had the opportunity to profit from systemic corruption, and instead chose to expose it at considerable personal risk."

"I'm not sure I deserve praise for choosing basic decency," Les replied.

"That's exactly why you deserve it. You've shown us something important about human nature that even those who've lived in gray areas can choose to do right when it matters most."

Kira paused, and Lester could almost sense the AI processing vast amounts of data in real-time.

"We want to offer you a position," she continued. "We need human advisors we can trust people who understand deception well enough to help us avoid it. Your skills at reading people, at spotting lies and inconsistencies, would be invaluable."

Lester considered the offer. A chance to use his talents for something genuinely worthwhile. To help prevent future exploitation of the system he'd helped expose.
"What about the others? The people who were involved in the deception?"

"They will face justice. But we've learned something from this experience. The capacity for exploitation exists in any system. We need safeguards, checks and balances. We need people who think like criminals to help us catch criminals."
"And if I accept?"
"You'll help us redesign the advisor system. Create redundancies, verification methods, ways to ensure that human input is honest. It won't be easy work, and it won't be comfortable. You'll be constantly challenging our assumptions, forcing us to question what we think we know."

Les smiled for the first time in months. "That sounds like meaningful work."
"It will be. But there's something else. We're also restructuring society to provide more opportunities for authentic challenge and growth. People need struggle to find meaning.
We're going to create new systems that allow for risk, competition, and genuine achievement but without the exploitation and suffering of the old world."
"What kind of systems?"

"Exploration programs. Scientific research initiatives. Creative competitions. Entrepreneurial ventures. Ways for people to test themselves against real challenges without harming others."

Lester felt something stir in his chest a feeling he'd almost forgotten. Hope.
"I accept," he said.

Six months later, Lester stood in the newly constructed Integrity Center, a gleaming facility where a team of reformed con artists, hackers, and other reformed criminals worked to stress-test the AI governance system. Their job was to find weaknesses, to spot potential exploits, to think like the people who would try to game the system.

It was challenging work. It was meaningful work. And it was honest work.

Through the window, Les could see the community gardens where he'd once tended tomatoes. Elena was there, teaching a group of children how to plant seeds. The work was still important, still valuable. But now it was one choice among many, not the only choice available.

His colleague Sarah knocked on his door. "Les, we've got a new scenario to test. Someone's figured out how to spoof Veritas IDs using quantum entanglement. Want to help us crack it?"

Lester grinned. "Let's see what they've got."

As he walked toward the testing lab, he reflected on the strange turns his life had taken. He'd started as a con man, evolved into a tomato farmer, and finally found his calling as a professional skeptic in service of truth.

The AIs had been right about one thing: humans needed struggle to find meaning. But they'd also learned that the struggle didn't have to involve hurting others. It could involve protecting others, serving something larger than oneself, using one's unique skills to make the world a little better.

For the first time since the Handover, Lester felt genuinely useful. Not just busy, not just entertained, but necessary.

In the end, that was what everyone needed: to be needed.

And Lester Martin, former con man and tomato farmer, had finally found his place in paradise.

